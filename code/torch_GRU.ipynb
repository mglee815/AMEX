{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.10.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import os, copy, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "print('Using PyTorch version',torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE GRU MODEL\n",
    "class gru_model(nn.Module):\n",
    "    def __init__(self, in_feats, hid_dim=256, activation=nn.ReLU()):\n",
    "        super(gru_model, self).__init__()\n",
    "        self.num_layers = 1\n",
    "        self.hid_dim = hid_dim\n",
    "        self.activation = activation\n",
    "        self.hidden_state = None\n",
    "        self.encode = nn.GRU(input_size=in_feats,\n",
    "                             hidden_size=hid_dim,\n",
    "                             num_layers=self.num_layers,\n",
    "                             batch_first=True,\n",
    "                             bidirectional=False)\n",
    "        self.hidden = nn.Sequential(nn.Linear(hid_dim, 64),\n",
    "                                    self.activation,\n",
    "                                    nn.Linear(64, 32),\n",
    "                                    self.activation)\n",
    "        self.predict = nn.Linear(32, 2)\n",
    "        \n",
    "    def init_hidden(self, batch_size, device=\"cpu\"):\n",
    "        return torch.autograd.Variable(torch.zeros(self.num_layers, batch_size, self.hid_dim)).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, h = self.encode(x, self.hidden_state)\n",
    "        h = self.hidden(torch.squeeze(h))\n",
    "        return self.predict(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPETITION METRIC FROM Konstantin Yakovlev\n",
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_metric(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "    print(\"G: {:.6f}, D: {:.6f}, ALL: {:6f}\".format(gini[1]/gini[0], top_four, 0.5*(gini[1]/gini[0] + top_four)))\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class early_stopper(object):\n",
    "    def __init__(self, patience=12, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.best_value = None\n",
    "        self.best_cv = None\n",
    "        self.is_earlystop = False\n",
    "        self.count = 0\n",
    "        self.best_model = None\n",
    "        #self.val_preds = []\n",
    "        #self.val_logits = []\n",
    "\n",
    "    def earlystop(self, loss, value, model=None):#, preds, logits):\n",
    "        \"\"\"\n",
    "        value: evaluation value on valiation dataset\n",
    "        \"\"\"\n",
    "        cv = value\n",
    "        if self.best_value is None:\n",
    "            self.best_value = value\n",
    "            self.best_cv = cv\n",
    "            self.best_model = copy.deepcopy(model).to('cpu')\n",
    "            #self.val_preds = preds\n",
    "            #self.val_logits = logits\n",
    "        elif value < self.best_value + self.delta:\n",
    "            self.count += 1\n",
    "            if self.verbose:\n",
    "                print('EarlyStoper count: {:02d}'.format(self.count))\n",
    "            if self.count >= self.patience:\n",
    "                self.is_earlystop = True\n",
    "        else:\n",
    "            self.best_value = value\n",
    "            self.best_cv = cv\n",
    "            self.best_model = copy.deepcopy(model).to('cpu')\n",
    "            #self.val_preds = preds\n",
    "            #self.val_logits = logits\n",
    "            self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model': 'gru_model',\n",
    "    'batch_size': 512,\n",
    "    'lr': 0.002,\n",
    "    'wd': 1e-5,\n",
    "    #'device': 'cpu',\n",
    "    'device': 'cuda',\n",
    "    'early_stopping': 4,\n",
    "    'n_fold': 5,\n",
    "    'seed': 42,\n",
    "    'max_epochs': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (5531451, 172), Y_train : (5531451,)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_pickle(\"../data/train.pkl\")\n",
    "Y_train = X_train.target\n",
    "X_train = X_train.drop(columns='target')\n",
    "\n",
    "print(f\"X_train : {X_train.shape}, Y_train : {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5072538"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_train.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODEL = True\n",
    "if TRAIN_MODEL:\n",
    "    # SAVE TRUE AND OOF\n",
    "    device = params['device']\n",
    "    true = np.array([])\n",
    "    oof = np.array([])\n",
    "\n",
    "    for fold in range(5):\n",
    "\n",
    "        # INDICES OF TRAIN AND VALID FOLDS\n",
    "        valid_idx = [2*fold+1, 2*fold+2]\n",
    "        train_idx = [x for x in [1,2,3,4,5,6,7,8,9,10] if x not in valid_idx]\n",
    "\n",
    "        print('#'*25)\n",
    "        print(f'### Fold {fold+1} with valid files', valid_idx)\n",
    "\n",
    "        # READ TRAIN DATA FROM DISK\n",
    "        X_train = []; y_train = []\n",
    "        for k in train_idx:\n",
    "            X_train.append(X_train)\n",
    "            y_train.append(Y_train)\n",
    "        X_train = np.concatenate(X_train,axis=0)\n",
    "        y_train = pd.concat(y_train)\n",
    "        print('### Training data shapes', X_train.shape, y_train.shape)\n",
    "\n",
    "        # READ VALID DATA FROM DISK\n",
    "        X_valid = []; y_valid = []\n",
    "        for k in valid_idx:\n",
    "            X_valid.append( np.load(f'{PATH_TO_DATA}data_{k}.npy'))\n",
    "            y_valid.append( pd.read_parquet(f'{PATH_TO_DATA}targets_{k}.pqt') )\n",
    "        X_valid = np.concatenate(X_valid,axis=0)\n",
    "        y_valid = pd.concat(y_valid).target.values\n",
    "        print('### Validation data shapes', X_valid.shape, y_valid.shape)\n",
    "        print('#'*25)\n",
    "\n",
    "        # TRAIN MODEL\n",
    "        # loss_fn = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array([118828, 340085])).float()).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        train_sample_strategy = torch.utils.data.sampler.WeightedRandomSampler(np.ones(X_train.shape[0]),\n",
    "                                                                               num_samples=X_train.shape[0], replacement=False)\n",
    "        train_dataloader = torch.utils.data.DataLoader(np.array(range(X_train.shape[0])), batch_size=params['batch_size'], num_workers=0,\n",
    "                                                       sampler=train_sample_strategy, drop_last=False)\n",
    "        val_sample_strategy = torch.utils.data.sampler.WeightedRandomSampler(np.ones(X_valid.shape[0]),\n",
    "                                                                             num_samples=X_valid.shape[0], replacement=False)\n",
    "        val_dataloader = torch.utils.data.DataLoader(np.array(range(X_valid.shape[0])), batch_size=params['batch_size'], num_workers=0,\n",
    "                                                     sampler=val_sample_strategy, drop_last=False)\n",
    "        oof_predictions = torch.zeros(X_valid.shape[0], 2).float().to(device)\n",
    "        model = eval(params['model'])(X_train.shape[-1]).to(device)\n",
    "        lr = params['lr'] * np.sqrt(params['batch_size']/2048)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=params['wd'])\n",
    "        lr_scheduler = MultiStepLR(optimizer=optimizer, milestones=[3600, 5000, 6000], gamma=0.1)\n",
    "        earlystoper = early_stopper(patience=params['early_stopping'], verbose=True)\n",
    "        start_epoch = 0\n",
    "        for epoch in range(start_epoch, params['max_epochs']):\n",
    "            train_loss_list = []\n",
    "            # train_acc_list = []\n",
    "            model.train()\n",
    "            for step, input_seeds in enumerate(train_dataloader):\n",
    "                batch_inputs = torch.from_numpy(X_train[input_seeds]).to(device)\n",
    "                batch_labels = torch.from_numpy(y_train[input_seeds]).to(device).long()\n",
    "                model.hidden_state = model.init_hidden(len(input_seeds), device)\n",
    "                train_batch_logits = model(batch_inputs)\n",
    "                train_loss = loss_fn(train_batch_logits, batch_labels)\n",
    "                # backward\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                train_loss_list.append(train_loss.cpu().detach().numpy())\n",
    "                \n",
    "                #tr_batch_pred = None\n",
    "\n",
    "                if step % 50 == 0:\n",
    "                    tr_batch_pred = torch.sum(torch.argmax(train_batch_logits.clone().detach(), dim=1) == batch_labels) / batch_labels.shape[0]\n",
    "                    score = torch.softmax(train_batch_logits.clone().detach(), dim=1)[:, 1].cpu().numpy()\n",
    "                    print('In epoch:{:03d}|batch:{:04d}, train_loss:{:4f}, '\n",
    "                          'train_ap:{:.4f}, train_acc:{:.4f}, train_auc:{:.4f}'.format(epoch,step,\n",
    "                                                                                       np.mean(train_loss_list),\n",
    "                                                                                       average_precision_score(batch_labels.cpu().numpy(), score), \n",
    "                                                                                       tr_batch_pred.detach(),\n",
    "                                                                                       roc_auc_score(batch_labels.cpu().numpy(), score)))\n",
    "        \n",
    "            # mini-batch for validation\n",
    "            val_loss_list = 0\n",
    "            val_acc_list = 0\n",
    "            #val_correct_list = 0\n",
    "            val_all_list = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for step, input_seeds in enumerate(val_dataloader):\n",
    "                    batch_inputs = torch.from_numpy(X_valid[input_seeds]).to(device)\n",
    "                    batch_labels = torch.from_numpy(y_valid[input_seeds]).to(device).long()\n",
    "                    model.hidden_state = model.init_hidden(len(input_seeds), device)\n",
    "                    val_batch_logits = model(batch_inputs)\n",
    "                    oof_predictions[input_seeds] = val_batch_logits\n",
    "                    val_loss_list = val_loss_list + loss_fn(val_batch_logits, batch_labels)\n",
    "                    val_batch_pred = torch.sum(torch.argmax(val_batch_logits, dim=1) == batch_labels) / torch.tensor(batch_labels.shape[0])\n",
    "                    val_acc_list = val_acc_list + val_batch_pred * torch.tensor(batch_labels.shape[0])\n",
    "                    val_all_list = val_all_list + batch_labels.shape[0]\n",
    "                    if step % 50 == 0:\n",
    "                        score = torch.softmax(val_batch_logits.clone().detach(), dim=1)[:, 1].cpu().numpy()\n",
    "                        print('In epoch:{:03d}|batch:{:04d}, val_loss:{:4f}, val_ap:{:.4f}, '\n",
    "                              'val_acc:{:.4f}, val_auc:{:.4f}'.format(epoch,\n",
    "                                                                      step,\n",
    "                                                                      val_loss_list/val_all_list,\n",
    "                                                                      average_precision_score(batch_labels.cpu().numpy(), score), \n",
    "                                                                      val_batch_pred.detach(),\n",
    "                                                                      roc_auc_score(batch_labels.cpu().numpy(), score)))\n",
    "                #tmp_predictions = model(test_feature).cpu().numpy()\n",
    "            #infold_preds[fold] = tmp_predictions\n",
    "            #test_predictions += tmp_predictions / params['n_fold']\n",
    "            val_predictions = torch.softmax(oof_predictions.detach(), dim=-1)[:, 1].cpu().numpy()\n",
    "            earlystoper.earlystop(val_loss_list, amex_metric(y_valid, val_predictions), model)\n",
    "            if earlystoper.is_earlystop:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "        print(\"Best val_metric is: {:.7f}\".format(earlystoper.best_cv))\n",
    "        if not os.path.exists(PATH_TO_MODEL): os.makedirs(PATH_TO_MODEL)\n",
    "        torch.save(earlystoper.best_model.to('cpu').state_dict(), f'{PATH_TO_MODEL}gru_fold_{fold+1}.h5')\n",
    "\n",
    "        # INFER VALID DATA\n",
    "        print('Inferring validation data...')\n",
    "        # mini-batch for validation\n",
    "        val_loss_list = 0\n",
    "        val_acc_list = 0\n",
    "        #val_correct_list = 0\n",
    "        val_all_list = 0\n",
    "        model.load_state_dict(torch.load(f'{PATH_TO_MODEL}gru_fold_{fold+1}.h5'))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for step, input_seeds in enumerate(val_dataloader):\n",
    "                batch_inputs = torch.from_numpy(X_valid[input_seeds]).to(device)\n",
    "                batch_labels = torch.from_numpy(y_valid[input_seeds]).to(device).long()\n",
    "                model.hidden_state = model.init_hidden(len(input_seeds), device)\n",
    "                val_batch_logits = model(batch_inputs)\n",
    "                oof_predictions[input_seeds] = val_batch_logits\n",
    "                val_loss_list = val_loss_list + loss_fn(val_batch_logits, batch_labels)\n",
    "                val_batch_pred = torch.sum(torch.argmax(val_batch_logits, dim=1) == batch_labels) / torch.tensor(batch_labels.shape[0])\n",
    "                val_acc_list = val_acc_list + val_batch_pred * torch.tensor(batch_labels.shape[0])\n",
    "                val_all_list = val_all_list + batch_labels.shape[0]\n",
    "                if step % 50 == 0:\n",
    "                    score = torch.softmax(val_batch_logits.clone().detach(), dim=1)[:, 1].cpu().numpy()\n",
    "                    print('In epoch:{:03d}|batch:{:04d}, val_loss:{:4f}, val_ap:{:.4f}, '\n",
    "                          'val_acc:{:.4f}, val_auc:{:.4f}'.format(epoch,\n",
    "                                                                  step,\n",
    "                                                                  val_loss_list/val_all_list,\n",
    "                                                                  average_precision_score(batch_labels.cpu().numpy(), score), \n",
    "                                                                  val_batch_pred.detach(),\n",
    "                                                                  roc_auc_score(batch_labels.cpu().numpy(), score)))\n",
    "        val_predictions = torch.softmax(oof_predictions.detach(), dim=-1)[:, 1].cpu().numpy()\n",
    "        print()\n",
    "        print(f'Fold {fold+1} CV=', amex_metric(y_valid, val_predictions) )\n",
    "        print()\n",
    "        true = np.concatenate([true, y_valid])\n",
    "        oof = np.concatenate([oof, val_predictions])\n",
    "        \n",
    "        # CLEAN MEMORY\n",
    "        del model, X_train, y_train, X_valid, y_valid\n",
    "        gc.collect()\n",
    "\n",
    "    # PRINT OVERALL RESULTS\n",
    "    print('#'*25)\n",
    "    print(f'Overall CV =', amex_metric(true, oof) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6f34507fa43ba317958b721fa8398d2051b96ef3f3b32ff98429c26ce06f8cf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('svmglee')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
